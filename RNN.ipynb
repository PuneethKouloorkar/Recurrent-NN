{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R9jDhZRkz3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDUYrDAFlCJU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "de72778e-9e30-4f7d-deb3-aa0c8ed4538e"
      },
      "source": [
        "with np.load('/content/drive/My Drive/DL data/RNN/rnn-challenge-data.npz') as fs:\n",
        "    data_x = fs['data_x']\n",
        "    data_y = fs['data_y']\n",
        "    valid_x = fs['val_x']\n",
        "    valid_y = fs['val_y']\n",
        "    test_x = fs['test_x']\n",
        "\n",
        "for i in [data_x, data_y, valid_x, valid_y, test_x]:\n",
        "    print(i.shape)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(400,)\n",
            "(400,)\n",
            "(100,)\n",
            "(100,)\n",
            "(250,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_EzzAlPl6hc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "b5f99739-f53f-4b98-818d-36ffd31b826b"
      },
      "source": [
        "print(data_x[:5])\n",
        "print(data_y[:5])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['CTAGCTGAGCTACTGAGCTACAGTTGACTGACCAGTCAGTGCTAGCTACTGACAGTCTGACAGTTGACCTGACTGATGACCAGTCTAGCAGTGCTACTAGCTAGGCTACAGTCAGTTGACCAGTCTGACAGTCAGTCTGACTGACAGTCAGTCTAGGCTATGACCTGACTGATGACCTGACTGACTGACAGTCTGACTGATGACGCTATGACCTGACTAGCTAGCAGTTGACTGACCTGACAGTGCTACTAGCAGTTGACCAGTGCTACAGTCTGATGACTGACCTGACAGTCTAGGCTACAGTTGACCTGACAGTCAGTGCTACTGACAGTCTAGTGACCAGTCAGTCAGTTGACCTGACTAGCAGTTGACGCTATGACCAGTCTGACAGTGCTACTAG'\n",
            " 'TGACGCTAGCTAGCTAAGTCACGTTGACAGTCACGTACGTAGTCACGTAGTCGCTAGCTAAGTCACGTGCTACAGTGCTATGACAGTCGCTAACGTTGACACGTACGTTGACCAGTGCTAGCTAGCTAGCTAACGTCAGTCAGTGCTATGACGCTAGCTATGACTGACGCTAACGTTGACTGACAGTCACGTAGTCAGTCACGTAGTCAGTCGCTAGCTAGCTAAGTCACGTCAGTACGTGCTAACGTTGACAGTCCAGTCAGTAGTCACGTACGTGCTAAGTCGCTAAGTCAGTCAGTCACGTACGTGCTAAGTCACGTCAGTCAGTAGTCAGTCACGTACGTACGTCAGTACGTAGTCCAGTGCTAGCTAACGTTGACGCTAACGTACGTAGTCACGT'\n",
            " 'AGTCACGTAGTCAGTCGCTAGCTAACGTACGTCAGTGCTACAGTCAGTCAGTGCTAGCTAGCTAAGTCACGTTGACGCTACAGTCAGTCAGTACGTCAGTAGTCACGTTGACCAGTCAGTAGTCAGTCACGTTGACGCTAACGTAGTCAGTCACGTAGTCAGTCCAGTCAGTGCTAACGTAGTCGCTATGACACGTACGTGCTACAGTCAGTAGTCCAGTGCTAAGTCACGTAGTCGCTAACGTAGTCAGTCGCTAGCTAAGTCACGTCAGTCAGTCAGTAGTCCAGTGCTACAGTAGTCGCTATGACCAGTCAGTGCTAACGTCAGTCAGTCAGTGCTAAGTCGCTAGCTAAGTCAGTCCAGTGCTATGACCAGTACGTCAGTACGTACGTAGTCGCTA'\n",
            " 'GTCAGTCACTGACAGTGTCACAGTCTGACTGACTGAGTCAGATCAGTCGTCACAGTGTCAAGTCGTCAAGTCAGTCAGTCAGTCCAGTCTGAGATCCTGACAGTAGTCGATCAGTCCAGTCTGACTGAGATCCTGAGTCACTGACTGACAGTGTCAGTCACAGTGATCGATCCAGTGATCCTGAGATCAGTCAGTCAGTCGTCACTGAGATCCAGTCTGACTGACTGAGATCAGTCCAGTGATCCTGAAGTCCAGTAGTCAGTCAGTCGTCACTGAGATCGATCCAGTCAGTCTGAGATCGTCACTGACTGAAGTCAGTCGATCGATCAGTCGTCACAGTGTCACAGTGATCAGTCGTCACAGTGATCGTCAGATCCTGAGTCACTGAGATCCTGACAGT'\n",
            " 'CAGTGATCCAGTCTAGGATCGATCCTAGCTAGGTCACTAGGATCCTGACTGAGTCAGATCCTAGCTAGGTCAGATCCAGTCTAGGTCAGTCAGATCCTGAGATCCAGTCTGAGTCAGATCCTAGCTAGGTCACTGACTGAGTCAGATCCTAGCAGTGATCGTCACAGTCTGACTAGGTCAGATCGATCGATCCTGAGTCAGTCACTGACTGAGTCACTGACAGTCTGAGTCACAGTCTGACAGTCTAGCTAGGTCAGATCGTCACAGTGATCCTGACTGAGTCACTAGGTCACAGTGATCGTCAGTCACTGAGATCGTCACTGAGTCAGATCGTCAGTCACAGTGTCACTGACTAGGATCGTCACTAGCTGACAGTGATCCTAGCAGTGTCAGATCGTCA']\n",
            "[2 0 0 4 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dAE8cQUzIeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = ['A', 'C', 'G', 'T']   \n",
        "\n",
        "def one_hot(vocab, seq):       # one hot encode train_x, val_x and test_x\n",
        "    eye = np.eye(4)\n",
        "    return np.array([eye[vocab.index(i)] for i in seq])"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE6zYF7y2k5z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "f546f026-e27f-4e41-9f83-12ab9ae6124a"
      },
      "source": [
        "train_x = np.array([one_hot(vocab, i) for i in data_x])\n",
        "val_x = np.array([one_hot(vocab, i) for i in valid_x])\n",
        "test_x = np.array([one_hot(vocab, i) for i in test_x])\n",
        "print(train_x.shape)\n",
        "print(val_x.shape)\n",
        "print(test_x.shape)\n",
        "train_x = torch.Tensor(train_x)\n",
        "val_x = torch.Tensor(val_x)\n",
        "train_y = torch.Tensor(data_y)\n",
        "val_y = torch.Tensor(valid_y)\n",
        "test_x = torch.Tensor(test_x)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(400, 400, 4)\n",
            "(100, 1200, 4)\n",
            "(250, 2000, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXDE9VaT6Ytd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 50\n",
        "val_batch_size = 100\n",
        "vocab = [\"A\", \"C\", \"G\", \"T\"]\n",
        "n_classes = 5\n",
        "n_hidden = 256\n",
        "\n",
        "class LSTM(torch.nn.Module):\n",
        "    def __init__(self, vocab, n_classes, n_hidden=256, n_layers=2):\n",
        "        super().__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.n_hidden = n_hidden\n",
        "        self.vocab = vocab\n",
        "        self.rnn = torch.nn.LSTM(input_size=len(vocab), hidden_size=n_hidden, num_layers=n_layers, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(n_hidden, n_classes)\n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        return self.fc(out), hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return torch.zeros(2, self.n_layers, batch_size, self.n_hidden)\n",
        "\n",
        "net = LSTM(vocab=vocab, n_classes=n_classes)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA3_odAa8Fe1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = TensorDataset(train_x, train_y)\n",
        "trainloader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val = TensorDataset(val_x,val_y)\n",
        "valloader = DataLoader(val, batch_size=val_batch_size, shuffle=False)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sk85UcRP7SgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optim = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XwXRN2h69mS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stretch_flat(tensor, times):           # used for labels in loss calculation\n",
        "    assert len(tensor.shape) == 1\n",
        "    return tensor.unsqueeze(0).repeat(times,1).T.flatten()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wffzsxgq9sGs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "1d006a0f-4185-49b0-989e-398c6bc41978"
      },
      "source": [
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i, data in enumerate(trainloader):\n",
        "        h = net.init_hidden(batch_size)\n",
        "        h = tuple([each.data for each in h])\n",
        "        inputs, labels = data\n",
        "        net.zero_grad()\n",
        "        pred, h = net(inputs, h)\n",
        "        loss = loss_fn(pred.view(-1, n_classes), stretch_flat(labels, times=400).long())\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(net.parameters(), 5)\n",
        "        optim.step()\n",
        "\n",
        "    print(f'iteration:{epoch}\\tCross Entropy Loss:{loss.item()}')\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration:0\tCross Entropy Loss:1.6081641912460327\n",
            "iteration:1\tCross Entropy Loss:1.6095649003982544\n",
            "iteration:2\tCross Entropy Loss:1.6092818975448608\n",
            "iteration:3\tCross Entropy Loss:1.6106510162353516\n",
            "iteration:4\tCross Entropy Loss:1.6108566522598267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lLUN3dcAhtf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_acc = 0\n",
        "train_accuracy = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in trainloader:\n",
        "        h = net.init_hidden(batch_size)\n",
        "        h = tuple([each.data for each in h])\n",
        "        inputs, labels = data\n",
        "        output, h = net(inputs, h)\n",
        "        output = torch.nn.LogSoftmax(dim=0)(output)\n",
        "        #print(output[0])\n",
        "        sums = output.sum(axis=1)\n",
        "        #print(sums.shape)\n",
        "        pred = sums.max(axis=1).indices\n",
        "        train_acc += len((pred == labels).nonzero())\n",
        "    train_accuracy.append(train_acc / len(data_x))"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvvtClvZE4my",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d4e7dd62-7f22-45c3-ba95-5d338bbb360c"
      },
      "source": [
        "print(train_accuracy[-1])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK46M0ZljX6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_acc = 0\n",
        "val_accuracy = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in valloader:\n",
        "        h = net.init_hidden(val_batch_size)\n",
        "        h = tuple([each.data for each in h])\n",
        "        inputs, labels = data\n",
        "        output, h = net(inputs, h)\n",
        "        output = torch.nn.LogSoftmax(dim=0)(output)\n",
        "        sums = output.sum(axis=1)\n",
        "        pred = sums.max(axis=1).indices\n",
        "        val_acc += len((pred == labels).nonzero())\n",
        "    val_accuracy.append(val_acc / len(val_x))"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uxJz5AXjwiQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f9f2896-6440-4d14-a65f-3cf56e50401e"
      },
      "source": [
        "print(val_accuracy[-1])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdoKk-rLj2zb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 56,
      "outputs": []
    }
  ]
}